{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Platform:  linux\n",
      "System Python Version: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:16:10) [GCC 13.3.0]\n",
      "PyTorch version 2.6.0\n",
      "Numpy version 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import os # type: ignore\n",
    "import time # type: ignore\n",
    "import random # type: ignore\n",
    "import sys # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "\n",
    "from tqdm import tqdm # type: ignore\n",
    "\n",
    "import torch # type: ignore\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.nn.functional as F # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "from torch.utils.data import Dataset, DataLoader # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "import uproot as ur # type: ignore\n",
    "import pickle # type: ignore\n",
    "\n",
    "print(\"System Platform: \", sys.platform)\n",
    "print('System Python Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Numpy version', np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = None, None\n",
    "pickled_data_file_path = \"transformed_data.pkl\"\n",
    "pickled_labels_file_path = \"transformed_labels.pkl\"\n",
    "if os.path.exists(pickled_data_file_path) and os.path.exists(pickled_labels_file_path):\n",
    "    with open(pickled_data_file_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open(pickled_labels_file_path, 'rb') as f:\n",
    "        y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is None or y is None:\n",
    "    background_data_file_name = \"train_bkg_data_sideBands_lowQ_wPreselBDT_v5.root\"\n",
    "    signal_data_file_name = \"train_sig_rare_lowQ_wPreselBDT_v6.root\"\n",
    "\n",
    "    background_data_file = ur.open(background_data_file_name)\n",
    "    signal_data_file = ur.open(signal_data_file_name)\n",
    "    features = ['Bprob', 'BsLxy', 'L2iso/L2pt', 'Bcos', 'Kiso/Kpt', 'LKdz', 'LKdr', 'Passymetry', 'Kip3d/Kip3dErr', 'L1id', 'L2id']\n",
    "    sample_weights = 'trig_wgt'\n",
    "    preselection = '(KLmassD0 > 2.) & ((Mll>1.05) & (Mll<2.45))'\n",
    "\n",
    "    sig_dict = signal_data_file['mytree'].arrays(features, library='np', cut=preselection)\n",
    "    bkg_dict = background_data_file['mytree'].arrays(features, library='np', cut=preselection)\n",
    "    backgr = np.stack(list(bkg_dict.values()))\n",
    "    signal = np.stack(list(sig_dict.values()))\n",
    "\n",
    "    X = np.transpose(np.concatenate((signal, backgr), axis=1))\n",
    "    y = np.concatenate((np.ones(signal.shape[1]), np.zeros(backgr.shape[1])))\n",
    "\n",
    "    with open(pickled_data_file_path, 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "    with open(pickled_labels_file_path, 'wb') as f:\n",
    "        pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (2553918, 11)\n",
      "Validation set: (547268, 11)\n",
      "Test set: (547269, 11)\n"
     ]
    }
   ],
   "source": [
    "random_seed = 7\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_seed)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset & DataLoader Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __call__(self, data: np.ndarray):\n",
    "        return data\n",
    "\n",
    "class Normalize(Transform):\n",
    "    def __call__(self, data: np.ndarray):\n",
    "        data = data.astype(np.float64)\n",
    "\n",
    "        min_values = np.min(data, axis=0)\n",
    "        max_values = np.max(data, axis=0)\n",
    "\n",
    "        data -= min_values\n",
    "        data /= (max_values - min_values)\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticlesDataset(Dataset):\n",
    "    def __init__(self, data: np.ndarray, labels: np.ndarray, transform: Transform = Transform()):\n",
    "        if data.shape[0] != labels.shape[0]:\n",
    "            raise RuntimeError(\"Training data and training labels have size mismatch:\", self.__class__.__name__)\n",
    "        \n",
    "        self.data = torch.tensor(transform(data), dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index], self.labels[index])\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return ['Background', 'Signal']\n",
    "    \n",
    "    @property\n",
    "    def features(self):\n",
    "        return ['Bprob', 'BsLxy', 'L2iso/L2pt', 'Bcos', 'Kiso/Kpt', 'LKdz', 'LKdr', 'Passymetry', 'Kip3d/Kip3dErr', 'L1id', 'L2id']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = ParticlesDataset(data=X_train, labels=y_train, transform=Normalize())\n",
    "training_dataloader = DataLoader(dataset=training_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "validation_dataset = ParticlesDataset(data=X_val, labels=y_val, transform=Normalize())\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "test_dataset = ParticlesDataset(data=X_test, labels=y_test, transform=Normalize())\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow/Narrow Architecture:\n",
    "This will be a very simple and smaller model that will act as a performance baseline. It won't have very many layers or very many nodes in each layer. \n",
    "Below is the original starting point I used for this architecture, this may be subject to change. \n",
    "\n",
    "Original Layers:\n",
    "\n",
    "    Input ReLU Linear 12 -> 32\n",
    "\n",
    "    Hidden ReLU Linear 32 -> 16\n",
    "\n",
    "    Output Sigmoid Linear 16 -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNarrowModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShallowNarrowModel, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(11,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_narrow_model = ShallowNarrowModel()\n",
    "num_epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=shallow_narrow_model.parameters(), lr=0.001)\n",
    "training_losses, validation_losses = [], []\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "shallow_narrow_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in num_epochs:\n",
    "    shallow_narrow_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for events, labels in tqdm(training_dataloader, desc=\"Training Loop: Shallow Narrow Model\"):\n",
    "        events, labels = events.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = shallow_narrow_model(events)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backwards()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(training_dataloader.dataset)\n",
    "    training_losses.append(train_loss)\n",
    "\n",
    "    shallow_narrow_model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for events, labels in tqdm(validation_dataloader, desc=\"Validation Loop: Shallow Narrow Model\"):\n",
    "            events, labels = events.to(device), labels.to(device)\n",
    "            outputs = shallow_narrow_model(events)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        val_loss = running_loss / len(validation_dataloader.dataset)\n",
    "        validation_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses, label='Training loss')\n",
    "plt.plot(validation_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep/Narrow Architecture:\n",
    "There will be more layers in this model, but the amount of nodes per layer will remain relatively smaller. The amount of nodes per layer will also remain balanced.\n",
    "Below is the original starting point I used for this architecture, this may be subject to change. \n",
    "\n",
    "Original Layers:\n",
    "\n",
    "    Input ReLU Linear 12 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLU Linear 32 -> 16\n",
    "\n",
    "    Output Sigmoid Linear 16 -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow/Wide Architecture: There will be relatively less layers in this one, but more nodes in each one. \n",
    "Below is the original starting point I used for this architecture, this may be subject to change. \n",
    "\n",
    "Original Layers:\n",
    "\n",
    "    Input ReLU Linear 12 -> 64\n",
    "\n",
    "    Hidden ReLU Linear 64 -> 128\n",
    "\n",
    "    Hidden ReLU Linear 128 -> 64\n",
    "\n",
    "    Hidden ReLU Linear 64 -> 32\n",
    "\n",
    "    Hidden ReLU Linear 32 -> 16\n",
    "\n",
    "    Output Sigmoid Linear 16 -> 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
