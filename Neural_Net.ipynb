{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "from tqdm import tqdm # type: ignore\n",
    "\n",
    "import torch # type: ignore\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.nn.functional as F # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "from torch.utils.data import Dataset, DataLoader # type: ignore\n",
    "\n",
    "import uproot as ur # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_data_file_name = \"train_bkg_data_sideBands_lowQ_wPreselBDT_v5.root\"\n",
    "signal_data_file_name = \"train_sig_rare_lowQ_wPreselBDT_v6.root\"\n",
    "\n",
    "background_data_file = ur.open(background_data_file_name)\n",
    "signal_data_file = ur.open(signal_data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow/Narrow Architecture:\n",
    "This will be a very simple and smaller model that will act as a performance baseline. It won't have very many layers or very many nodes in each layer. \n",
    "Below is the original starting point I used for this architecture, this may be subject to change. \n",
    "\n",
    "Original Layers:\n",
    "\n",
    "    Input ReLU Linear 12 -> 32\n",
    "\n",
    "    Hidden ReLU Linear 32 -> 16\n",
    "\n",
    "    Output Sigmoid Linear 16 -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep/Narrow Architecture:\n",
    "There will be more layers in this model, but the amount of nodes per layer will remain relatively smaller. The amount of nodes per layer will also remain balanced.\n",
    "Below is the original starting point I used for this architecture, this may be subject to change. \n",
    "\n",
    "Original Layers:\n",
    "\n",
    "    Input ReLU Linear 12 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLu Linear 32 -> 32\n",
    "\n",
    "    Hidden ReLU Linear 32 -> 16\n",
    "\n",
    "    Output Sigmoid Linear 16 -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow/Wide Architecture: There will be relatively less layers in this one, but more nodes in each one. \n",
    "Below is the original starting point I used for this architecture, this may be subject to change. \n",
    "\n",
    "Original Layers:\n",
    "\n",
    "    Input ReLU Linear 12 -> 64\n",
    "\n",
    "    Hidden ReLU Linear 64 -> 128\n",
    "\n",
    "    Hidden ReLU Linear 128 -> 64\n",
    "\n",
    "    Hidden ReLU Linear 64 -> 32\n",
    "\n",
    "    Hidden ReLU Linear 32 -> 16\n",
    "\n",
    "    Output Sigmoid Linear 16 -> 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
